{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientGAN_L1",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HiWtQ-D1LuS",
        "outputId": "ae5662fd-17c2-4899-e513-7a2ba6ff555f"
      },
      "source": [
        "!wget https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/rp73yg93n8-1.zip -nc -P ./data/\n",
        "!unzip -n ./data/rp73yg93n8-1.zip -d ./data/\n",
        "!unzip -n -q ./data/fruits-360_dataset.zip -d ./data/ "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-30 01:46:58--  https://md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com/rp73yg93n8-1.zip\n",
            "Resolving md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com (md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com)... 52.218.49.75\n",
            "Connecting to md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com (md-datasets-cache-zipfiles-prod.s3.eu-west-1.amazonaws.com)|52.218.49.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 418811602 (399M) [application/octet-stream]\n",
            "Saving to: ‘./data/rp73yg93n8-1.zip’\n",
            "\n",
            "rp73yg93n8-1.zip    100%[===================>] 399.41M  30.7MB/s    in 14s     \n",
            "\n",
            "2020-11-30 01:47:12 (28.7 MB/s) - ‘./data/rp73yg93n8-1.zip’ saved [418811602/418811602]\n",
            "\n",
            "Archive:  ./data/rp73yg93n8-1.zip\n",
            "  inflating: ./data/fruits-360_dataset.zip  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYRcBmau09Fe"
      },
      "source": [
        "import random\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from natsort import natsorted\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import torch.nn.init as init\n",
        "from torchsummary import summary\n",
        "from warnings import filterwarnings\n",
        "filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwuvr4sM1i6D",
        "outputId": "9448ccb4-2841-4198-d27b-1c2da919936c"
      },
      "source": [
        "IMAGE_SIZE = 96\n",
        "EMBED_SIZE = 128\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "EPOCHS = 1000\n",
        "LR = 0.0004\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "\n",
        "COLAB_FLG = True\n",
        "\n",
        "if COLAB_FLG:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    ATTACH_PATH = \"/content/drive/My Drive/PyTorch-GAN/\"\n",
        "else:\n",
        "    ATTACH_PATH = \".\"\n",
        "    \n",
        "\n",
        "SAVE_MODEL_PATH = f\"{ATTACH_PATH}/results/EfficientGAN_L1/model/\"\n",
        "SAVE_IMAGE_FROM_Z_PATH = f\"{ATTACH_PATH}/results/EfficientGAN_L1/image/image_from_z/\"\n",
        "SAVE_IMAGE_RECONSTRUCT = f\"{ATTACH_PATH}/results/EfficientGAN_L1/image/RECONSTRUCT/\"\n",
        "\n",
        "os.makedirs(SAVE_MODEL_PATH, exist_ok=True)\n",
        "os.makedirs(SAVE_IMAGE_FROM_Z_PATH, exist_ok=True)\n",
        "os.makedirs(SAVE_IMAGE_RECONSTRUCT, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7M3O8Zp1x3T"
      },
      "source": [
        "train_root = './data/fruits-360/Training/Physalis/'\n",
        "val_root = './data/fruits-360/Test/Physalis/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfiY2ICx18_a"
      },
      "source": [
        "class LoadFromFolder(Dataset):\n",
        "    def __init__(self, main_dir, transform):\n",
        "        self.main_dir = main_dir\n",
        "        self.transform = transform\n",
        "        all_imgs = natsorted(os.listdir(main_dir))\n",
        "        self.all_imgs_name = natsorted(all_imgs)\n",
        "        self.imgs_loc = [os.path.join(self.main_dir, i) for i in self.all_imgs_name]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_imgs_name)\n",
        "    \n",
        "    def load_image(self, path):\n",
        "        image = Image.open(path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(image)\n",
        "        return tensor_image\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        if type(idx) == slice:\n",
        "            paths = self.imgs_loc[idx]\n",
        "            tensor_image = [self.load_image(path) for path in paths]\n",
        "            tensor_image = torch.cat(tensor_image).reshape(len(tensor_image), *tensor_image[0].shape)\n",
        "        elif type(idx) == int:\n",
        "            path = self.imgs_loc[idx]\n",
        "            tensor_image = self.load_image(path)\n",
        "        return tensor_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4MFxTvY1-HR"
      },
      "source": [
        "transform_dict = {\n",
        "    \"train\": transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "        ]\n",
        "    ),\n",
        "    \"test\": transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "            transforms.ToTensor(),\n",
        "        ]\n",
        "    ),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae2oEOAq2DYj"
      },
      "source": [
        "train_dataset = LoadFromFolder(train_root, transform=transform_dict[\"train\"])\n",
        "\n",
        "val_dataset = LoadFromFolder(val_root, transform=transform_dict[\"test\"])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, **kwargs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kevxkqv2E7r"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2), #48x48\n",
        "            \n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2), #24x24\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2), #12x12\n",
        "            \n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2), #6x6\n",
        "\n",
        "        \n",
        "            nn.Conv2d(256, 512, kernel_size=6, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2), #1x1\n",
        "\n",
        "            nn.Conv2d(512, 512, kernel_size=1, stride=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2), #1x1\n",
        "        )\n",
        "        \n",
        "        self.last = nn.Sequential(\n",
        "            nn.Conv2d(512, EMBED_SIZE, kernel_size=1, stride=1, bias=False)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        out = self.main(x)\n",
        "\n",
        "        out = self.last(out)\n",
        "        out = out.view(out.size()[0], -1, 1, 1)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QB0NKNP2OQU",
        "outputId": "a447e33d-3722-4e8f-d7d4-b60eb73ad21e"
      },
      "source": [
        "summary(Encoder().to(device), (3, 96, 96))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 48, 48]           1,536\n",
            "       BatchNorm2d-2           [-1, 32, 48, 48]              64\n",
            "         LeakyReLU-3           [-1, 32, 48, 48]               0\n",
            "            Conv2d-4           [-1, 64, 24, 24]          32,768\n",
            "       BatchNorm2d-5           [-1, 64, 24, 24]             128\n",
            "         LeakyReLU-6           [-1, 64, 24, 24]               0\n",
            "            Conv2d-7          [-1, 128, 12, 12]         131,072\n",
            "       BatchNorm2d-8          [-1, 128, 12, 12]             256\n",
            "         LeakyReLU-9          [-1, 128, 12, 12]               0\n",
            "           Conv2d-10            [-1, 256, 6, 6]         524,288\n",
            "      BatchNorm2d-11            [-1, 256, 6, 6]             512\n",
            "        LeakyReLU-12            [-1, 256, 6, 6]               0\n",
            "           Conv2d-13            [-1, 512, 1, 1]       4,718,592\n",
            "      BatchNorm2d-14            [-1, 512, 1, 1]           1,024\n",
            "        LeakyReLU-15            [-1, 512, 1, 1]               0\n",
            "           Conv2d-16            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-17            [-1, 512, 1, 1]           1,024\n",
            "        LeakyReLU-18            [-1, 512, 1, 1]               0\n",
            "           Conv2d-19            [-1, 128, 1, 1]          65,536\n",
            "================================================================\n",
            "Total params: 5,738,944\n",
            "Trainable params: 5,738,944\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.11\n",
            "Forward/backward pass size (MB): 3.19\n",
            "Params size (MB): 21.89\n",
            "Estimated Total Size (MB): 25.19\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esutYM5S2PLN"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(EMBED_SIZE, 256, kernel_size=6, stride=1, padding=0, bias=False), # 6x6\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False), # 12x12\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False), # 24x24\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1, bias=False), # 48x48\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(32, 3, kernel_size=4, stride=2, padding=1, bias=False), #96x96\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.main(z)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnuFK2vt2QNj",
        "outputId": "b858868a-2c11-4ee4-e3e3-c4b80bc470ea"
      },
      "source": [
        "summary(Generator().to(device), tuple([EMBED_SIZE, 1, 1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "   ConvTranspose2d-1            [-1, 256, 6, 6]       1,179,648\n",
            "       BatchNorm2d-2            [-1, 256, 6, 6]             512\n",
            "         LeakyReLU-3            [-1, 256, 6, 6]               0\n",
            "   ConvTranspose2d-4          [-1, 128, 12, 12]         524,288\n",
            "       BatchNorm2d-5          [-1, 128, 12, 12]             256\n",
            "         LeakyReLU-6          [-1, 128, 12, 12]               0\n",
            "   ConvTranspose2d-7           [-1, 64, 24, 24]         131,072\n",
            "       BatchNorm2d-8           [-1, 64, 24, 24]             128\n",
            "         LeakyReLU-9           [-1, 64, 24, 24]               0\n",
            "  ConvTranspose2d-10           [-1, 32, 48, 48]          32,768\n",
            "      BatchNorm2d-11           [-1, 32, 48, 48]              64\n",
            "        LeakyReLU-12           [-1, 32, 48, 48]               0\n",
            "  ConvTranspose2d-13            [-1, 3, 96, 96]           1,536\n",
            "             Tanh-14            [-1, 3, 96, 96]               0\n",
            "================================================================\n",
            "Total params: 1,870,272\n",
            "Trainable params: 1,870,272\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.59\n",
            "Params size (MB): 7.13\n",
            "Estimated Total Size (MB): 10.72\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "davQzb5s2RCj"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "            \n",
        "        self.x_layer = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "            # nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.1, inplace=True), #48x48\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            \n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.1, inplace=True), #24x24\n",
        "            nn.Dropout2d(p=0.3),\n",
        "\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.1, inplace=True), #12x12\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            \n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.1, inplace=True), #6x6\n",
        "            nn.Dropout2d(p=0.3),\n",
        "            \n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Conv2d(256, 256, kernel_size=6, stride=1) #1x1\n",
        "\n",
        "        )\n",
        "        self.z_layer = nn.Sequential(\n",
        "            nn.Conv2d(EMBED_SIZE, 256, kernel_size=1, stride=1),\n",
        "            nn.LeakyReLU(0.1, inplace=True),\n",
        "            nn.Dropout2d(p=0.2),\n",
        "            \n",
        "\n",
        "            \n",
        "        )\n",
        "        \n",
        "        self.last1 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=1, stride=1),\n",
        "            nn.LeakyReLU(0.1, inplace=False),\n",
        "            nn.Dropout2d(p=0.2),\n",
        "            \n",
        "            \n",
        " \n",
        "        )\n",
        "        self.last2 = nn.Sequential(\n",
        "            nn.Conv2d(512, 1, kernel_size=1, stride=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, z):\n",
        "        \n",
        "        output_x = self.x_layer(x)\n",
        "        output_z = self.z_layer(z)\n",
        "        \n",
        "        concat_x_z = torch.cat((output_x, output_z), 1)\n",
        "        output = self.last1(concat_x_z)\n",
        "\n",
        "        feature = output.view(output.size()[0], -1)\n",
        "        \n",
        "        output = self.last2(output)\n",
        "        output = F.sigmoid(output)\n",
        "        return output.squeeze(), feature"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw608EcU2S6q",
        "outputId": "8ee7ef0c-4807-4b5c-b45b-92324f9cc958"
      },
      "source": [
        "summary(Discriminator().to(device), [(3, IMAGE_SIZE, IMAGE_SIZE), (EMBED_SIZE, 1, 1)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 96, 96]             896\n",
            "         LeakyReLU-2           [-1, 32, 96, 96]               0\n",
            "         Dropout2d-3           [-1, 32, 96, 96]               0\n",
            "         AvgPool2d-4           [-1, 32, 48, 48]               0\n",
            "            Conv2d-5           [-1, 64, 48, 48]          18,496\n",
            "       BatchNorm2d-6           [-1, 64, 48, 48]             128\n",
            "         LeakyReLU-7           [-1, 64, 48, 48]               0\n",
            "         Dropout2d-8           [-1, 64, 48, 48]               0\n",
            "         AvgPool2d-9           [-1, 64, 24, 24]               0\n",
            "           Conv2d-10          [-1, 128, 24, 24]          73,856\n",
            "      BatchNorm2d-11          [-1, 128, 24, 24]             256\n",
            "        LeakyReLU-12          [-1, 128, 24, 24]               0\n",
            "        Dropout2d-13          [-1, 128, 24, 24]               0\n",
            "        AvgPool2d-14          [-1, 128, 12, 12]               0\n",
            "           Conv2d-15          [-1, 256, 12, 12]         295,168\n",
            "      BatchNorm2d-16          [-1, 256, 12, 12]             512\n",
            "        LeakyReLU-17          [-1, 256, 12, 12]               0\n",
            "        Dropout2d-18          [-1, 256, 12, 12]               0\n",
            "        AvgPool2d-19            [-1, 256, 6, 6]               0\n",
            "           Conv2d-20            [-1, 256, 1, 1]       2,359,552\n",
            "           Conv2d-21            [-1, 256, 1, 1]          33,024\n",
            "        LeakyReLU-22            [-1, 256, 1, 1]               0\n",
            "        Dropout2d-23            [-1, 256, 1, 1]               0\n",
            "           Conv2d-24            [-1, 512, 1, 1]         262,656\n",
            "        LeakyReLU-25            [-1, 512, 1, 1]               0\n",
            "        Dropout2d-26            [-1, 512, 1, 1]               0\n",
            "           Conv2d-27              [-1, 1, 1, 1]             513\n",
            "================================================================\n",
            "Total params: 3,045,057\n",
            "Trainable params: 3,045,057\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 13.50\n",
            "Forward/backward pass size (MB): 15.70\n",
            "Params size (MB): 11.62\n",
            "Estimated Total Size (MB): 40.82\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4REWg4I_2T-7"
      },
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "    elif classname.find(\"Linear\") != -1:\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMSAKVRt2VKK"
      },
      "source": [
        "model_E = Encoder().to(device)\n",
        "model_E.apply(weights_init)\n",
        "\n",
        "model_G = Generator().to(device)\n",
        "model_G.apply(weights_init)\n",
        "\n",
        "model_D = Discriminator().to(device)\n",
        "model_D.apply(weights_init)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "criterion_L1 = nn.L1Loss(reduction=\"sum\")\n",
        "\n",
        "optimizer_ge = torch.optim.Adam(list(model_G.parameters()) + list(model_E.parameters()), lr= 0.0004, betas=(0.5,0.999))\n",
        "optimizer_d = torch.optim.Adam(model_D.parameters(), lr= 0.0004,betas=(0.5,0.999))\n",
        "# optimizer_d = torch.optim.SGD(model_D.parameters(), lr=0.001, momentum=0.9)\n",
        "scheduler_ge = torch.optim.lr_scheduler.StepLR(optimizer_ge, step_size=50, gamma=0.9)\n",
        "scheduler_d = torch.optim.lr_scheduler.StepLR(optimizer_d, step_size=50, gamma=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTzoweBT2xyj"
      },
      "source": [
        "def Anomaly_score(x, E_x, G_E_x, Lambda=0.1):\n",
        "    \n",
        "    _,x_feature = model_D(x, E_x)\n",
        "    _,G_E_x_feature = model_D(G_E_x, E_x)\n",
        "    \n",
        "    residual_loss = criterion_L1(x, G_E_x)\n",
        "    discrimination_loss = criterion_L1(x_feature, G_E_x_feature)\n",
        "    \n",
        "    total_loss = (1-Lambda)*residual_loss + Lambda*discrimination_loss\n",
        "    total_loss = total_loss.item()\n",
        "\n",
        "    return total_loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4CTI_mb2WYL"
      },
      "source": [
        "loss_d_list, loss_ge_list, anomaly_score_list = [], [], []\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    loss_d_sum = 0\n",
        "    loss_ge_sum = 0\n",
        "    anomaly_score_sum = 0\n",
        "    \n",
        "    for i,(x, x_val) in enumerate(zip(train_loader, val_loader)):\n",
        "        \n",
        "        model_G.train()\n",
        "        model_D.train()\n",
        "        model_E.train()\n",
        "        # set values\n",
        "        y_true = Variable(torch.ones(x.size()[0])).to(device)\n",
        "        y_fake = Variable(torch.zeros(x.size()[0])).to(device)\n",
        "        \n",
        "        x = Variable(x).to(device)\n",
        "        z = Variable(init.normal(torch.Tensor(x.size()[0],EMBED_SIZE, 1, 1),mean=0,std=0.1)).to(device)\n",
        "        \n",
        "        # noise for discriminator\n",
        "        noise1 = Variable(torch.Tensor(x.size()).normal_(0, 0.1 * (EPOCHS - epoch) / EPOCHS),\n",
        "                          requires_grad=False).to(device)\n",
        "        noise2 = Variable(torch.Tensor(x.size()).normal_(0, 0.1 * (EPOCHS - epoch) / EPOCHS),\n",
        "                          requires_grad=False).to(device)\n",
        "\n",
        "        # discriminator\n",
        "        optimizer_d.zero_grad()\n",
        "        \n",
        "        E_x = model_E(x) \n",
        "        p_true, _ = model_D(x + noise1, E_x)\n",
        "        \n",
        "        G_z = model_G(z)\n",
        "        p_fake, _ = model_D(G_z + noise2, z)\n",
        "        \n",
        "        loss_d = criterion(p_true, y_true) + criterion(p_fake, y_fake)\n",
        "        loss_d.backward(retain_graph=True)\n",
        "        optimizer_d.step()\n",
        "        \n",
        "        # generator and encoder\n",
        "        optimizer_ge.zero_grad()\n",
        "        \n",
        "        G_E_x = model_G(E_x)\n",
        "        E_G_z = model_E(G_z)\n",
        "    \n",
        "        p_true, _ = model_D(x + noise1, E_x)\n",
        "        \n",
        "        # G_z = model_G(z)\n",
        "        p_fake, _ = model_D(G_z + noise2, z)\n",
        "        \n",
        "        \n",
        "        loss_ge_1 = criterion(p_fake, y_true) + criterion(p_true, y_fake)\n",
        "        loss_ge_2 = criterion_L1(x, G_E_x) +  criterion_L1(z, E_G_z)\n",
        "        \n",
        "        alpha = 0.01\n",
        "        \n",
        "        loss_ge = (1 - alpha)*loss_ge_1 + alpha*loss_ge_2\n",
        "        loss_ge.backward(retain_graph=True)\n",
        "        optimizer_ge.step()\n",
        "        \n",
        "        \n",
        "        loss_d_sum += loss_d.item()\n",
        "        loss_ge_sum += loss_ge.item()\n",
        "        \n",
        "        # record anomaly score\n",
        "        \n",
        "        model_G.eval()\n",
        "        model_D.eval()\n",
        "        model_E.eval()\n",
        "        x_val = Variable(x_val).to(device)\n",
        "        E_x_val = model_E(x_val)\n",
        "        G_E_x_val = model_G(E_x_val)\n",
        "        anomaly_score_sum += Anomaly_score(x_val, E_x_val, G_E_x_val)\n",
        "\n",
        "            \n",
        "        # save images\n",
        "        if i == 0:\n",
        "            \n",
        "            model_G.eval()\n",
        "            model_D.eval()\n",
        "            model_E.eval()\n",
        "        \n",
        "            save_image_size_for_z = min(BATCH_SIZE, 8)\n",
        "            save_images = model_G(z)\n",
        "            save_image(save_images[:save_image_size_for_z], f\"{SAVE_IMAGE_FROM_Z_PATH}/epoch_{epoch}.png\", nrow=4)\n",
        "\n",
        "            save_image_size_for_recon = min(BATCH_SIZE, 8)\n",
        "            images = x[:save_image_size_for_recon]\n",
        "            G_E_x = model_G(model_E(images))\n",
        "            diff_images = torch.abs(images - G_E_x)\n",
        "            comparison = torch.cat([images , G_E_x, diff_images]).to(\"cpu\")\n",
        "            save_image(comparison, f\"{SAVE_IMAGE_RECONSTRUCT}/epoch_{epoch}.png\", nrow=save_image_size_for_recon)\n",
        "            \n",
        "    scheduler_ge.step()\n",
        "    scheduler_d.step()\n",
        "        \n",
        "    # record loss\n",
        "    loss_d_mean = loss_d_sum / len(train_loader)\n",
        "    loss_ge_mean = loss_ge_sum / len(train_loader)\n",
        "    anomaly_score_mean = anomaly_score_sum / len(train_loader)\n",
        "    \n",
        "    print(f\"{epoch}/{EPOCHS} epoch ge_loss: {loss_ge_mean:.3f} d_loss: {loss_d_mean:.3f} anomaly_score: {anomaly_score_mean:.3f}\")\n",
        "    \n",
        "    loss_d_list.append(loss_d_mean)\n",
        "    loss_ge_list.append(loss_ge_mean)\n",
        "    anomaly_score_list.append(anomaly_score_mean)\n",
        "    \n",
        "    # save model\n",
        "    if epoch % 10 == 0:\n",
        "        torch.save(model_G.state_dict(),f'{SAVE_MODEL_PATH}/Generator_{epoch}.pkl')\n",
        "        torch.save(model_E.state_dict(),f'{SAVE_MODEL_PATH}/Encoder_{epoch}.pkl')\n",
        "        torch.save(model_D.state_dict(),f'{SAVE_MODEL_PATH}/Discriminator_{epoch}.pkl')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-EQHA9K2mVS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
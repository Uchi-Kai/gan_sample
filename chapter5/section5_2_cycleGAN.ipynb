{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "section5_2-cycleGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1k37EP-NRcI4"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVzTjlr1RgEt"
      },
      "source": [
        "## データの収集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHxNDyqmtTq1"
      },
      "source": [
        "import google.colab.drive\n",
        "google.colab.drive.mount('gdrive')\n",
        "!ls ./gdrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6iRSl53I8QB"
      },
      "source": [
        "## Googleドライブからデータをコピー"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCPUyGaeVe1x"
      },
      "source": [
        "!mkdir -p 'gdrive/MyDrive/cyclegan'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npLAi7tG7EKN"
      },
      "source": [
        "# photo2portraitデータセットのコピー\n",
        "!gdown --id 1arF3guFms5tLiaIs8GtcV2dW0WAvrvLM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5shm4mW-7X6"
      },
      "source": [
        "!ls /content\n",
        "!cp /content/photo2portrait.tar.gz ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czvnj0rfyySe"
      },
      "source": [
        "!tar -zxvf photo2portrait.tar.gz "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3N3ubXBmf7s"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ドメインAの学習データ\n",
        "img = plt.imread('./photo2portrait/train/A/000177.jpg')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2HUhVaunrlx"
      },
      "source": [
        "# ドメインBの学習データ\n",
        "img = plt.imread('./photo2portrait/train/B/000212.jpg')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmBZOEi0iZmz"
      },
      "source": [
        "## ライブラリのインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGmH0YUJ00Lj"
      },
      "source": [
        "!pip install torch>=0.4.1\n",
        "!pip install torchvision>=0.2.1\n",
        "!pip install dominate>=2.3.1\n",
        "!pip install visdom>=0.1.8.\n",
        "!pip install tensorboard\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgrzeMyBizIl"
      },
      "source": [
        "## インポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p32YbrVo_zp2"
      },
      "source": [
        "import glob\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime\n",
        "import sys\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from visdom import Visdom\n",
        "\n",
        "import itertools\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsU3jWCyCqWz"
      },
      "source": [
        "# ドメインAとドメインBの画像データセット生成クラス\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, root, transforms_=None, unaligned=False, mode='train'):\n",
        "        self.transform = transforms.Compose(transforms_)\n",
        "        self.unaligned = unaligned\n",
        "\n",
        "        self.files_A = sorted(glob.glob(os.path.join(root, '%s/A' % mode) + '/*.*'))\n",
        "        self.files_B = sorted(glob.glob(os.path.join(root, '%s/B' % mode) + '/*.*'))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item_A = self.transform(Image.open(self.files_A[index % len(self.files_A)]).convert('RGB'))\n",
        "\n",
        "        if self.unaligned:\n",
        "            item_B = self.transform(Image.open(self.files_B[random.randint(0, len(self.files_B) - 1)]).convert('RGB'))\n",
        "        else:\n",
        "            item_B = self.transform(Image.open(self.files_B[index % len(self.files_B)]).convert('RGB'))\n",
        "\n",
        "        return {'A': item_A, 'B': item_B}\n",
        "\n",
        "    def __len__(self):\n",
        "        return max(len(self.files_A), len(self.files_B))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gBu6xGSmd5a"
      },
      "source": [
        "# ネットワーク定義"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTuZ6WiDJikk"
      },
      "source": [
        "## Residual Block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIqw8ldJC8M0"
      },
      "source": [
        "# ResidualBlockの定義\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_features):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ReflectionPad2d(1),\n",
        "            nn.Conv2d(in_features, in_features, 3),\n",
        "            nn.InstanceNorm2d(in_features)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv_block(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGbQA7GbJo44"
      },
      "source": [
        "## 生成器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hw1c1UdoHyFe"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, n_residual_blocks=9):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(input_nc, 64, 7),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            ResidualBlock(256),\n",
        "            ResidualBlock(256),\n",
        "            ResidualBlock(256),\n",
        "            ResidualBlock(256),\n",
        "            ResidualBlock(256),\n",
        "            ResidualBlock(256),\n",
        "            ResidualBlock(256),\n",
        "            ResidualBlock(256),\n",
        "            ResidualBlock(256),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.InstanceNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.ReflectionPad2d(3),\n",
        "            nn.Conv2d(64, 3, 7),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MlFCLZ7Jru8"
      },
      "source": [
        "## 識別器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "det9xMBSHzvt"
      },
      "source": [
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(input_nc, 64, 4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(128), \n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256), \n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 512, 4, padding=1),\n",
        "            nn.InstanceNorm2d(512), \n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(512, 1, 4, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x =  self.model(x)\n",
        "        # Average pooling and flatten\n",
        "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51vJc4yZJ76d"
      },
      "source": [
        "## 生成画像のバッファ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocCNFv3LH_zV"
      },
      "source": [
        "# 過去の生成データ(50iter分)を保持しておく\n",
        "class ReplayBuffer():\n",
        "    def __init__(self, max_size=50):\n",
        "        self.max_size = max_size\n",
        "        self.data = []\n",
        "\n",
        "    def push_and_pop(self, data):\n",
        "        to_return = []\n",
        "        for element in data.data:\n",
        "            #\n",
        "            element = torch.unsqueeze(element, 0)\n",
        "            if len(self.data) < self.max_size:\n",
        "                self.data.append(element)\n",
        "                to_return.append(element)\n",
        "            else:\n",
        "                if random.uniform(0,1) > 0.5:\n",
        "                    i = random.randint(0, self.max_size-1)\n",
        "                    to_return.append(self.data[i].clone())\n",
        "                    self.data[i] = element\n",
        "                else:\n",
        "                    to_return.append(element)\n",
        "        return Variable(torch.cat(to_return))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ktxyHY8IFU_"
      },
      "source": [
        "class LambdaLR():\n",
        "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
        "        self.n_epochs = n_epochs\n",
        "        self.offset = offset\n",
        "        self.decay_start_epoch = decay_start_epoch\n",
        "\n",
        "    def step(self, epoch):\n",
        "        return 1.0 - max(0, epoch + self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
        "\n",
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        torch.nn.init.normal(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm2d') != -1:\n",
        "        torch.nn.init.normal(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant(m.bias.data, 0.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3P8RG5bm-VV"
      },
      "source": [
        "!mkdir -p output\n",
        "!ls output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrAeuzLDLBck"
      },
      "source": [
        "# 学習"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mAJNZZWLKTZ"
      },
      "source": [
        "## TensorboardでのLoss確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKeX0i4fuEID"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "log_dir = './logs'\n",
        "os.makedirs(log_dir, exist_ok=True)\n",
        "writer = SummaryWriter(log_dir=log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSMwSiXhuEuH"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "  \n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir './logs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsaCkC3pnUzY"
      },
      "source": [
        "## パラメータ設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rnf25wWnUDg"
      },
      "source": [
        "\n",
        "class Opts():\n",
        "    def __init__(self):\n",
        "        self.start_epoch = 0\n",
        "        self.n_epochs = 5\n",
        "        self.batch_size = 1\n",
        "        self.dataroot = './photo2portrait/'\n",
        "        self.lr = 0.0002\n",
        "        self.decay_epoch = 200\n",
        "        self.size = 256\n",
        "        self.input_nc = 3\n",
        "        self.output_nc = 3\n",
        "        self.cpu = False\n",
        "        self.n_cpu = 8\n",
        "        self.device_name = \"cuda:0\"\n",
        "        self.device = torch.device(self.device_name)\n",
        "        self.load_weight = False\n",
        "\n",
        "opt = Opts()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ll1vNozhMIgP"
      },
      "source": [
        "## ネットワーク呼び出し"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbowBgcODF9S"
      },
      "source": [
        "\n",
        "# 生成器\n",
        "netG_A2B = Generator(opt.input_nc, opt.output_nc)\n",
        "netG_B2A = Generator(opt.output_nc, opt.input_nc)\n",
        "\n",
        "# 識別器\n",
        "netD_A = Discriminator(opt.input_nc)\n",
        "netD_B = Discriminator(opt.output_nc)\n",
        "\n",
        "# GPU\n",
        "if not opt.cpu:\n",
        "    netG_A2B.cuda()\n",
        "    netG_B2A.cuda()\n",
        "    netD_A.cuda()\n",
        "    netD_B.cuda()\n",
        "\n",
        "# 重みパラメータ初期化\n",
        "netG_A2B.apply(weights_init_normal)\n",
        "netG_B2A.apply(weights_init_normal)\n",
        "netD_A.apply(weights_init_normal)\n",
        "netD_B.apply(weights_init_normal)\n",
        "\n",
        "# 保存したモデルのロード\n",
        "if opt.load_weight is True:\n",
        "    netG_A2B.load_state_dict(torch.load(\"./output/netG_A2B.pth\", map_location=\"cuda:0\"), strict=False)\n",
        "    netG_B2A.load_state_dict(torch.load(\"./output/netG_B2A.pth\", map_location=\"cuda:0\"), strict=False)\n",
        "    netD_A.load_state_dict(torch.load(\"./output/netD_A.pth\", map_location=\"cuda:0\"), strict=False)\n",
        "    netD_B.load_state_dict(torch.load(\"./output/netD_B.pth\", map_location=\"cuda:0\"), strict=False)\n",
        "\n",
        "# 損失関数\n",
        "criterion_GAN = torch.nn.MSELoss()\n",
        "criterion_cycle = torch.nn.L1Loss()\n",
        "criterion_identity = torch.nn.L1Loss()\n",
        "\n",
        "# Optimizers & LR schedulers\n",
        "optimizer_G = torch.optim.Adam(itertools.chain(netG_A2B.parameters(), netG_B2A.parameters()),\n",
        "                                lr=opt.lr, betas=(0.5, 0.999))\n",
        "optimizer_D_A = torch.optim.Adam(netD_A.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
        "optimizer_D_B = torch.optim.Adam(netD_B.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
        "\n",
        "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(opt.n_epochs, opt.start_epoch, opt.decay_epoch).step)\n",
        "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=LambdaLR(opt.n_epochs, opt.start_epoch, opt.decay_epoch).step)\n",
        "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=LambdaLR(opt.n_epochs, opt.start_epoch, opt.decay_epoch).step)\n",
        "\n",
        "# 入出力メモリ確保\n",
        "Tensor = torch.cuda.FloatTensor if not opt.cpu else torch.Tensor\n",
        "input_A = Tensor(opt.batch_size, opt.input_nc, opt.size, opt.size)\n",
        "input_B = Tensor(opt.batch_size, opt.output_nc, opt.size, opt.size)\n",
        "target_real = Variable(Tensor(opt.batch_size).fill_(1.0), requires_grad=False)\n",
        "target_fake = Variable(Tensor(opt.batch_size).fill_(0.0), requires_grad=False)\n",
        "\n",
        "# 過去データ分のメモリ確保\n",
        "fake_A_buffer = ReplayBuffer()\n",
        "fake_B_buffer = ReplayBuffer()\n",
        "\n",
        "# データローダー\n",
        "transforms_ = [ transforms.Resize(int(opt.size*1.12), Image.BICUBIC), \n",
        "                transforms.RandomCrop(opt.size), \n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
        "dataloader = DataLoader(ImageDataset(opt.dataroot, transforms_=transforms_, unaligned=True), \n",
        "                        batch_size=opt.batch_size, shuffle=True, num_workers=opt.n_cpu)\n",
        "\n",
        "print(\"num dataloader= {}\".format(len(dataloader)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FFdlE5Mr0cn"
      },
      "source": [
        "import torchsummary\n",
        "torchsummary.summary(netG_A2B, (opt.input_nc, opt.size, opt.size))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDaiBneDs47Z"
      },
      "source": [
        "torchsummary.summary(netD_A, (opt.input_nc, opt.size, opt.size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP62t2sNv1Mt"
      },
      "source": [
        "def save_loss(train_info, batches_done):\n",
        "    \"\"\"\n",
        "    lossの保存\n",
        "    \"\"\"\n",
        "    for k, v in train_info.items():\n",
        "        writer.add_scalar(k, v, batches_done)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIm3E7CSrrf9"
      },
      "source": [
        "## 学習の開始"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCB_0qiCDp9p"
      },
      "source": [
        "\n",
        "for epoch in range(opt.start_epoch, opt.n_epochs):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        # モデルの入力\n",
        "        real_A = Variable(input_A.copy_(batch['A']))\n",
        "        real_B = Variable(input_B.copy_(batch['B']))\n",
        "\n",
        "        ##### 生成器A2B、B2Aの処理 #####\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # 同一性損失の計算（Identity loss)\n",
        "        # G_A2B(B)はBと一致\n",
        "        same_B = netG_A2B(real_B)\n",
        "        loss_identity_B = criterion_identity(same_B, real_B)*5.0\n",
        "        # G_B2A(A)はAと一致\n",
        "        same_A = netG_B2A(real_A)\n",
        "        loss_identity_A = criterion_identity(same_A, real_A)*5.0\n",
        "\n",
        "        # 敵対的損失（GAN loss）\n",
        "        fake_B = netG_A2B(real_A)\n",
        "        pred_fake = netD_B(fake_B)\n",
        "        loss_GAN_A2B = criterion_GAN(pred_fake, target_real)\n",
        "\n",
        "        fake_A = netG_B2A(real_B)\n",
        "        pred_fake = netD_A(fake_A)\n",
        "        loss_GAN_B2A = criterion_GAN(pred_fake, target_real)\n",
        "\n",
        "        # サイクル一貫性損失（Cycle-consistency loss）\n",
        "        recovered_A = netG_B2A(fake_B)\n",
        "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A)*10.0\n",
        "\n",
        "        recovered_B = netG_A2B(fake_A)\n",
        "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B)*10.0\n",
        "\n",
        "        # 生成器の合計損失関数（Total loss）\n",
        "        loss_G = loss_identity_A + loss_identity_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n",
        "        loss_G.backward()\n",
        "        \n",
        "        optimizer_G.step()\n",
        "\n",
        "        ##### ドメインAの識別器 #####\n",
        "        optimizer_D_A.zero_grad()\n",
        "\n",
        "        # ドメインAの本物画像の識別結果（Real loss）\n",
        "        pred_real = netD_A(real_A)\n",
        "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
        "\n",
        "        # ドメインAの生成画像の識別結果（Fake loss）\n",
        "        fake_A = fake_A_buffer.push_and_pop(fake_A)\n",
        "        pred_fake = netD_A(fake_A.detach())\n",
        "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
        "\n",
        "        # 識別器（ドメインA）の合計損失（Total loss）\n",
        "        loss_D_A = (loss_D_real + loss_D_fake)*0.5\n",
        "        loss_D_A.backward()\n",
        "\n",
        "        optimizer_D_A.step()\n",
        "\n",
        "        ##### ドメインBの識別器 #####\n",
        "        optimizer_D_B.zero_grad()\n",
        "\n",
        "        # ドメインBの本物画像の識別結果（Real loss）\n",
        "        pred_real = netD_B(real_B)\n",
        "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
        "        \n",
        "        # ドメインBの生成画像の識別結果（Fake loss）\n",
        "        fake_B = fake_B_buffer.push_and_pop(fake_B)\n",
        "        pred_fake = netD_B(fake_B.detach())\n",
        "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
        "\n",
        "        # 識別器（ドメインB）の合計損失（Total loss）\n",
        "        loss_D_B = (loss_D_real + loss_D_fake)*0.5\n",
        "        loss_D_B.backward()\n",
        "\n",
        "        optimizer_D_B.step()\n",
        "        ###################################\n",
        "\n",
        "        if i % 20 == 0:\n",
        "            print('Epoch[{}]({}/{}) loss_G: {:.4f} loss_G_identity: {:.4f} loss_G_GAN: {:.4f} loss_G_cycle: {:.4f} loss_D: {:.4f}'.format(\n",
        "                epoch, i, len(dataloader), loss_G, (loss_identity_A + loss_identity_B),\n",
        "                (loss_GAN_A2B + loss_GAN_B2A), (loss_cycle_ABA + loss_cycle_BAB), (loss_D_A + loss_D_B)\n",
        "                ))\n",
        "\n",
        "        train_info = {\n",
        "            'epoch': epoch, \n",
        "            'batch_num': i, \n",
        "            'lossG': loss_G.item(),\n",
        "            'lossG_identity': (loss_identity_A.item() + loss_identity_B.item()),\n",
        "            'lossG_GAN': (loss_GAN_A2B.item() + loss_GAN_B2A.item()),\n",
        "            'lossG_cycle': (loss_cycle_ABA.item() + loss_cycle_BAB.item()),\n",
        "            'lossD': (loss_D_A.item() + loss_D_B.item()), \n",
        "            }\n",
        "\n",
        "        batches_done = (epoch - 1) * len(dataloader) + i\n",
        "        save_loss(train_info, batches_done)\n",
        "\n",
        "    # Update learning rates\n",
        "    lr_scheduler_G.step()\n",
        "    lr_scheduler_D_A.step()\n",
        "    lr_scheduler_D_B.step()\n",
        "\n",
        "    # Save models checkpoints\n",
        "    torch.save(netG_A2B.state_dict(), 'output/netG_A2B.pth')\n",
        "    torch.save(netG_B2A.state_dict(), 'output/netG_B2A.pth')\n",
        "    torch.save(netD_A.state_dict(), 'output/netD_A.pth')\n",
        "    torch.save(netD_B.state_dict(), 'output/netD_B.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHsGPRy_HxQ3"
      },
      "source": [
        "!ls output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfBTMvOzL70j"
      },
      "source": [
        "# テスト"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWlkreGEMDob"
      },
      "source": [
        "## パラメータ設定"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_7t6XvBBh4A"
      },
      "source": [
        "\n",
        "class Opts_test():\n",
        "    def __init__(self):\n",
        "        self.batch_size = 1\n",
        "        self.dataroot = './photo2portrait/'\n",
        "        self.size = 256\n",
        "        self.input_nc = 3\n",
        "        self.output_nc = 3\n",
        "        self.cpu = False\n",
        "        self.n_cpu = 8\n",
        "        self.device_name = \"cuda:0\"\n",
        "        self.device = torch.device(self.device_name)\n",
        "        self.load_weight = False\n",
        "        self.generator_A2B = 'output/netG_A2B.pth'\n",
        "        self.generator_B2A = 'output/netG_B2A.pth'\n",
        "        self.cuda = True\n",
        "\n",
        "opt2 = Opts_test()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Q1FYISMYTs"
      },
      "source": [
        "## ネットワーク呼び出し"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydm4o1-rDWgl"
      },
      "source": [
        "\n",
        "# 生成器G\n",
        "netG_A2B = Generator(opt2.input_nc, opt2.output_nc)\n",
        "netG_B2A = Generator(opt2.output_nc, opt2.input_nc)\n",
        "\n",
        "# CUDA\n",
        "if opt2.cuda:\n",
        "    netG_A2B.cuda()\n",
        "    netG_B2A.cuda()\n",
        "\n",
        "# Load state dicts\n",
        "netG_A2B.load_state_dict(torch.load(opt2.generator_A2B))\n",
        "netG_B2A.load_state_dict(torch.load(opt2.generator_B2A))\n",
        "\n",
        "# Set model's test mode\n",
        "netG_A2B.eval()\n",
        "netG_B2A.eval()\n",
        "\n",
        "# Inputs & targets memory allocation\n",
        "Tensor = torch.cuda.FloatTensor if opt2.cuda else torch.Tensor\n",
        "input_A = Tensor(opt2.batch_size, opt2.input_nc, opt2.size, opt2.size)\n",
        "input_B = Tensor(opt2.batch_size, opt2.output_nc, opt2.size, opt2.size)\n",
        "\n",
        "# Dataset loader\n",
        "transforms_ = [transforms.Resize(int(opt2.size*1.0), Image.BICUBIC), \n",
        "                transforms.RandomCrop(opt2.size), \n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)) ]\n",
        "dataloader = DataLoader(ImageDataset(opt2.dataroot, transforms_=transforms_, mode='train'), \n",
        "                        batch_size=opt2.batch_size, shuffle=False, num_workers=opt2.n_cpu)\n",
        "\n",
        "\n",
        "# 出力用フォルダ生成\n",
        "if not os.path.exists('output/A'):\n",
        "    os.makedirs('output/A')\n",
        "if not os.path.exists('output/B'):\n",
        "    os.makedirs('output/B')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2qwZHrTEXI7"
      },
      "source": [
        "## テスト実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaRzK-6bEYdy"
      },
      "source": [
        "##### 生成器Gによる画像生成　#####\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "num_create = 100\n",
        "\n",
        "for i, batch in enumerate(dataloader):\n",
        "    # Set model input\n",
        "    real_A = Variable(input_A.copy_(batch['A']))\n",
        "    real_B = Variable(input_B.copy_(batch['B']))\n",
        "\n",
        "    # Generate output\n",
        "    fake_B = 0.5*(netG_A2B(real_A).data + 1.0)\n",
        "    fake_A = 0.5*(netG_B2A(real_B).data + 1.0)\n",
        "\n",
        "    out_img1 = torch.cat([real_A, fake_B], dim=2)\n",
        "    out_img2 = torch.cat([real_B, fake_A], dim=2)\n",
        "\n",
        "    # Save image files\n",
        "    save_image(out_img1, 'output/A/%04d.png' % (i+1))\n",
        "    save_image(out_img2, 'output/B/%04d.png' % (i+1))\n",
        "\n",
        "    if i > num_create:\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tUVdjn2ETuU"
      },
      "source": [
        "## 生成画像の表示"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKI8OxfTWwPM"
      },
      "source": [
        "# A->Bの生成画像\n",
        "import matplotlib.pyplot as plt\n",
        "img = plt.imread('output/A/0001.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb7cnSqLXFJ0"
      },
      "source": [
        "# B->Aの生成画像\n",
        "img = plt.imread('output/B/0001.png')\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu6Dto8VMgyU"
      },
      "source": [
        "# 結果の取得"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scEXWVGsE_v2"
      },
      "source": [
        "## 生成画像をローカルにコピー"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yMOIyhcW48Z"
      },
      "source": [
        "from google.colab import files\n",
        "!tar -zcvf outputA.tar.gz output/A/*\n",
        "!tar -zcvf outputB.tar.gz output/B/*\n",
        "\n",
        "!cp \"outputA.tar.gz\" 'gdrive/MyDrive/cyclegan/'\n",
        "!cp \"outputB.tar.gz\" 'gdrive/MyDrive/cyclegan/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWHvhV0lEuJb"
      },
      "source": [
        "## モデルの保存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN9KoWUXNGP1"
      },
      "source": [
        "!ls output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX_uyyZXgJTO"
      },
      "source": [
        "!cp output/net*.pth 'gdrive/MyDrive/cyclegan/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LT4OwTdNCym"
      },
      "source": [
        "!ls 'gdrive/MyDrive/cyclegan/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ig7tAY_BOhNR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}